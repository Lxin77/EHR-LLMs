{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    预处理文本数据\n",
    "    - 移除去识别括号\n",
    "    - 移除编号列表\n",
    "    - 替换缩写\n",
    "    - 移除特定关键词\n",
    "    - 移除重复字符\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\[(.*?)\\]', '', text)  # 移除去识别括号\n",
    "    text = re.sub(r'[0-9]+\\.', '', text)  # 移除编号列表\n",
    "    text = re.sub(r'dr\\.', 'doctor', text)  # 替换缩写\n",
    "    text = re.sub(r'm\\.d\\.', 'md', text)  # 替换缩写\n",
    "    text = re.sub(r'admission date:', '', text)  # 移除特定关键词\n",
    "    text = re.sub(r'discharge date:', '', text)  # 移除特定关键词\n",
    "    text = re.sub(r'--|__|==', '', text)  # 移除重复字符\n",
    "    return text\n",
    "\n",
    "def preprocessing(df_notes):\n",
    "    \"\"\"\n",
    "    预处理数据框中的文本数据\n",
    "    - 填充缺失值\n",
    "    - 移除换行符和回车符\n",
    "    - 去除首尾空格\n",
    "    - 转换为小写\n",
    "    - 应用自定义预处理函数\n",
    "    - 移除多余的空白\n",
    "    \"\"\"\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].fillna(' ')  # 填充缺失值\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].str.replace('\\n', ' ')  # 移除换行符\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].str.replace('\\r', ' ')  # 移除回车符\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].apply(str.strip)  # 去除首尾空格\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].str.lower()  # 转换为小写\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].apply(preprocess_text)  # 应用自定义预处理函数\n",
    "    df_notes['TEXT'] = df_notes['TEXT'].apply(lambda x: \" \".join(x.split()))  # 移除多余的空白\n",
    "    return df_notes\n",
    "\n",
    "def save_text_chunks(texts, save_path, chunk_size=10):\n",
    "    \"\"\"\n",
    "    将文本数据按块保存到指定路径\n",
    "    - texts: 文本列表\n",
    "    - save_path: 保存路径\n",
    "    - chunk_size: 每个文件包含的文本块数量\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)  # 如果路径不存在，创建路径\n",
    "\n",
    "    for i in range(0, len(texts), chunk_size):\n",
    "        chunk = texts[i:i + chunk_size]  # 获取当前块\n",
    "        chunk_text = \"\\n\".join(chunk)  # 将块内文本合并为一个字符串\n",
    "        file_name = os.path.join(save_path, f'text_chunk_{i // chunk_size + 1}.txt')  # 生成文件名\n",
    "        with open(file_name, 'w', encoding='utf-8') as f:\n",
    "            f.write(chunk_text)  # 将文本写入文件\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CSV文件路径\n",
    "file_path ='NOTEEVENTS.csv'\n",
    "column_name = 'CATEGORY'\n",
    "\n",
    "# 初始化空的Series以存储聚合计数\n",
    "aggregated_counts = pd.Series(dtype=int)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORY\n",
      "Case Management         1934\n",
      "Consult                  196\n",
      "Discharge summary     119304\n",
      "ECG                   418102\n",
      "Echo                   91588\n",
      "General                16602\n",
      "Nursing               447112\n",
      "Nursing/other        1644994\n",
      "Nutrition              18836\n",
      "Pharmacy                 206\n",
      "Physician             283248\n",
      "Radiology            1044558\n",
      "Rehab Services         10862\n",
      "Respiratory            63478\n",
      "Social Work             5340\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 设置块大小\n",
    "chunk_size = 10000  # 根据系统内存容量调整\n",
    "\n",
    "# 读取CSV文件并进行分块处理\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size, usecols=[column_name]):\n",
    "    # 计算当前块的值计数并添加到聚合计数中\n",
    "    aggregated_counts = aggregated_counts.add(chunk[column_name].value_counts(), fill_value=0)\n",
    "\n",
    "# 将聚合计数转换为整数\n",
    "aggregated_counts = aggregated_counts.astype(int)\n",
    "\n",
    "# 打印聚合计数结果\n",
    "print(aggregated_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 25 files in the discharge directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 初始化一个空列表以存储过滤后的DataFrame\n",
    "filtered_chunks = []\n",
    "\n",
    "# 读取CSV文件并进行分块处理\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    # 过滤出类别为'Social Work'的记录\n",
    "    filtered_chunk = chunk[chunk['CATEGORY'] == 'Social Work']\n",
    "    filtered_chunks.append(filtered_chunk)\n",
    "\n",
    "# 将所有过滤后的块连接成一个DataFrame\n",
    "soc = pd.concat(filtered_chunks, ignore_index=True)\n",
    "\n",
    "# 应用预处理函数\n",
    "soc = preprocessing(soc)\n",
    "\n",
    "# 标记包含'discharge'的记录\n",
    "soc['discharge'] = soc['TEXT'].str.contains('discharge')\n",
    "\n",
    "# 提取包含'discharge'的文本记录\n",
    "discharge_notes = soc[soc['discharge']]['TEXT'].tolist()\n",
    "\n",
    "# 输出文件夹路径\n",
    "output_dir = 'discharge'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 将每十行文本保存为一个单独的txt文件\n",
    "save_text_chunks(discharge_notes, output_dir, chunk_size=5)\n",
    "\n",
    "print(f\"Saved {len(discharge_notes)//5 + 1} files in the {output_dir} directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
