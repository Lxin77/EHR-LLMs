{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name emilyalsentzer/Bio_ClinicalBERT. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# some comment\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    ")\n",
    " \n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_211.txt\n"
     ]
    }
   ],
   "source": [
    "#onlyfiles = [f for f in listdir('top_1000_txt') if isfile(join('top_1000_txt', f))]\n",
    "onlyfiles=['note_211.txt']\n",
    "raw_documents = []\n",
    "for file in onlyfiles:\n",
    "    print(file)\n",
    "    raw_doc = TextLoader(f'top_1000_txt/{file}').load()\n",
    "    raw_documents.extend(raw_doc)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:30<00:00, 15.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"johnsnowlabs/JSL-MedLlama-3-8B-v2.0\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"johnsnowlabs/JSL-MedLlama-3-8B-v2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 设置 Hugging Face 管道\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=3000,\n",
    "    truncation=True,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "# 创建本地 LLM\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# 创建检索器\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# 创建 QA 链\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=local_llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=local_llm\n",
    "template = \"\"\"You are an expert clinical assistant. You will receive a collection of clinical notes. You will summarize them in the style of a discharge summary.Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Allergic to'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('What allergies did the patient have?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"Has the patient got a history of diabetes?\",\n",
    "    \"What allergies did the patient have?\",\n",
    "    \"Does the patient use tobacco or alcohol?\",\n",
    "    \"What medication is the patient taking?\",\n",
    "    \"What measures were taken for the patient?\",\n",
    "    \"What imaging studies were performed on the patient?\",\n",
    "    \"What follow-up care was scheduled for the patient?\",\n",
    "    \"What did C-spine show?\",\n",
    "    \"Does the patient use alcohol?\",\n",
    "    \"Does the patient use cigarettes or alcohol?\",\n",
    "    \"Did patient use tobacco?\"\n",
    "]\n",
    "\n",
    "ground_truths = [[\"No.\"],\n",
    "                 [\"The patient has no known allergies to drugs.\"],\n",
    "                 [\"Yes, the patient occasionally uses tobacco (cigarettes) but denies alcohol use.\"],\n",
    "                 [\"Dilantin 100 IV TID.\"],\n",
    "                 [\"Intubation and placement of a left radial arterial line for close blood pressure monitoring with a goal of keeping systolic blood pressure under 140. head CT, C-spine, chest/abdomen/pelvis CT to assess injuries. The patient was started on Dilantin 100 IV TID. Monitoring in the Trauma Intensive Care Unit (TICU). Repeat head CT and gradual weaning. Discontinuation of the Foley catheter and intravenous lines.Transfer from the ICU to the general hospital floor.  MRI of the C-spine to evaluate for potential injuries, which showed no fractures or ligamentous injuries, leading to clearance of the C-spine and discontinuation of the C-collar.Evaluation by Neurosurgery and Physical Therapy, deeming the patient fit for discharge with instructions for home care and follow-up.\"],\n",
    "                 [\"The patient underwent head CT, C-spine, chest/abd/pelvis CT scans, and an MRI of the C-spine\"],\n",
    "                 [\"An outpatient CT scan was scheduled to be done in 2 weeks, and a follow-up clinic appointment was scheduled in 2 weeks after the CT scan.No need to follow up in the trauma clinic but the patient may call the clinic with any questions.\"],\n",
    "                 [\"The MRI of the C-spine showed no fractures or ligamentous injuries.\"],\n",
    "                 [\"No, the patient denies alcohol use.\"],\n",
    "                 [\"The patient occasionally uses cigarettes and denies alcohol use.\"],\n",
    "                 [\"Yes, the patient occasionally uses tobacco (cigarettes).\"]\n",
    "\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
       "    num_rows: 11\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 11/11 [00:00<00:00, 618.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('JSL-MedLlama-3-8B-v2.0-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has the patient got a history of diabetes?</td>\n",
       "      <td>Yes, the patient has a history of diabetes.</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[No.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What allergies did the patient have?</td>\n",
       "      <td>Allergic to</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[The patient has no known allergies to drugs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does the patient use tobacco or alcohol?</td>\n",
       "      <td>Answer: The patient occasionally uses tobacco ...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Yes, the patient occasionally uses tobacco (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What medication is the patient taking?</td>\n",
       "      <td>The answer is Dilantin.</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Dilantin 100 IV TID.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What measures were taken for the patient?</td>\n",
       "      <td>The answer is: The patient was given Dilantin ...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Intubation and placement of a left radial art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  \\\n",
       "0  Has the patient got a history of diabetes?   \n",
       "1        What allergies did the patient have?   \n",
       "2    Does the patient use tobacco or alcohol?   \n",
       "3      What medication is the patient taking?   \n",
       "4   What measures were taken for the patient?   \n",
       "\n",
       "                                              answer  \\\n",
       "0        Yes, the patient has a history of diabetes.   \n",
       "1                                        Allergic to   \n",
       "2  Answer: The patient occasionally uses tobacco ...   \n",
       "3                            The answer is Dilantin.   \n",
       "4  The answer is: The patient was given Dilantin ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Patient recorded as having No Known Allergies...   \n",
       "1  [Patient recorded as having No Known Allergies...   \n",
       "2  [Patient recorded as having No Known Allergies...   \n",
       "3  [Patient recorded as having No Known Allergies...   \n",
       "4  [Patient recorded as having No Known Allergies...   \n",
       "\n",
       "                                       ground_truths  \n",
       "0                                              [No.]  \n",
       "1     [The patient has no known allergies to drugs.]  \n",
       "2  [Yes, the patient occasionally uses tobacco (c...  \n",
       "3                             [Dilantin 100 IV TID.]  \n",
       "4  [Intubation and placement of a left radial art...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_input_df = dataset.to_pandas()\n",
    "display(ragas_input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_ragas_dataset(dataset):\n",
    "  result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "    \n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:02<00:00, 62.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_correctness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "qa_result = evaluate_ragas_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.2727, 'faithfulness': 0.7273, 'answer_relevancy': 0.8613, 'context_recall': 1.0000, 'context_relevancy': 0.1193, 'answer_correctness': 0.8750, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = qa_result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"JSL-MedLlama-3-8B-v2.0-dataset_ragas_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
