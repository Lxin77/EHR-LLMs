{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name emilyalsentzer/Bio_ClinicalBERT. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# some comment\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    ")\n",
    " \n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_1227.txt\n"
     ]
    }
   ],
   "source": [
    "#onlyfiles = [f for f in listdir('top_1000_txt') if isfile(join('top_1000_txt', f))]\n",
    "onlyfiles=['note_1227.txt']\n",
    "raw_documents = []\n",
    "for file in onlyfiles:\n",
    "    print(file)\n",
    "    raw_doc = TextLoader(f'23 txt/{file}').load()\n",
    "    raw_documents.extend(raw_doc)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_417.txt\n"
     ]
    }
   ],
   "source": [
    "#onlyfiles = [f for f in listdir('top_1000_txt') if isfile(join('top_1000_txt', f))]\n",
    "onlyfiles=['note_417.txt']\n",
    "raw_documents = []\n",
    "for file in onlyfiles:\n",
    "    print(file)\n",
    "    raw_doc = TextLoader(f'23 txt/{file}').load()\n",
    "    raw_documents.extend(raw_doc)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 设置 Hugging Face 管道\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=3000,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "# 创建本地 LLM\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# 创建检索器\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# 创建 QA 链\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=local_llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"google/flan-t5-small\",\n",
    "    task=\"text2text-generation\",\n",
    "    model_kwargs={\"max_length\": 3000},\n",
    ")\n",
    "\n",
    "template = \"\"\"You are an expert clinical assistant. You will receive a collection of clinical notes. Your task is to retrieve relevant information from these notes and give an answer in response to the question. Answer the question accurately based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Does the patient have diabetes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1228.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#1227\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What will make patient return to the hospital?\",\n",
    "    \"What was patient found in left parietal?\",\n",
    "    \"What was patient diagnosed with?\",\n",
    "    \"What dose patient present from nursing home?\",\n",
    "    \"What was patient started on?\",\n",
    "    \"Does the patient have diabetes?\",\n",
    "    \"Did the patient have hypertension?\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"The patient will return to the hospital if experiencing chest pain, shortness of breath, high fever, or any mental status change.\"],\n",
    "    [\"He was found to have an embolic stroke in left parietal, left internal capsule region.\"],\n",
    "    [\"He was diagnosed with HIT and Afib.\"],\n",
    "    [\"Tachypnea for 2 days, intermittent fevers.\"],\n",
    "    [\"Dialysis.\"],\n",
    "    [\"Yes.\"],\n",
    "    [\"Yes.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-1227txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1395.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#1031\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What is the patient's age and gender?\",\n",
    "    \"What did the patient have a history of?\",\n",
    "    \"Why did the patient come to the hospital?\",\n",
    "    \"What medications was she discharged with?\",\n",
    "    \"What were the patient's vital signs on admission?\",\n",
    "    \"Did the patient have no known drug allergies?\",\n",
    "    \"What did the patient use tobacco, alcohol, and other drug?\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"The patient is a 57-year-old female.\"],\n",
    "    [\"Hypertension and hypercholesterolemia.\"],\n",
    "    [\"She came due to chest pain that started at 4:00 p.m.\"],\n",
    "    [\"She was discharged on Aspirin, Lisinopril, Toprol XL, Coumadin, Plavix, Lovenox, and Pravastatin.\"],\n",
    "    [\"Vital signs: On admission, the patient was afebrile, blood pressure 146/88, pulse 71, respirations 18.\"],\n",
    "    [\"Yes\"],\n",
    "    [\"The patient reported no tobacco use and denied any alcohol or other drug use.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-1031txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1465.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#1025\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What did the chest x-ray show?\",\n",
    "    \"What is the patient’s code status?\",\n",
    "    \"What did the patient undergo?\",\n",
    "    \"What are the patient's primary medical problems?\",\n",
    "    \"What imaging studies were performed?\",\n",
    "    \"When was the patient made DNR/DNI?\",\n",
    "    \"What did serial chest x-ray show?\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"Moderate cardiomegaly with some bilateral opacifications in the left upper and right upper lobes with multifocal pneumonia.\"],\n",
    "    [\"he patient was made DNR/DNI after multiple discussions with her family.\"],\n",
    "    [\"The patient underwent a sleep and swallow study and modified barium study.\"],\n",
    "    [\"Multiple medical problems including atrial fibrillation, chronic obstructive pulmonary disease, coronary artery disease, congestive heart failure.\"],\n",
    "    [\"Serial Chest X-rays, chest CT Scan.\"],\n",
    "    [\"the patient was made DNR/DNI after multiple discussions with her family, as well as proxyholder.\"],\n",
    "    [\"Serial chest x-ray showed moderate cardiomegaly with some bilateral opacifications in the left upper and right upper lobes with multifocal pneumonia.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-1025txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1277.81 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#1019\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What is the patient's age and gender?\",\n",
    "    \"What is the patient's past medical history?\",\n",
    "    \"Does the patient have any known drug allergies?\",\n",
    "    \"What is the patient's vital signs on arrival at the hospital?\",\n",
    "    \"What is the patient's diagnosis?\",\n",
    "    \"What were the results of the electrolyte panel?\",\n",
    "    \"What were the results of the CBC (Complete Blood Count)?\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"The patient is an 83-year-old female.\"],\n",
    "    [\"The patient has a history of hypertension and hypercholesterolemia.\"],\n",
    "    [\"No known drug allergies.\"],\n",
    "    [\"Temperature 97.0, blood pressure 133/77, pulse 51, respiratory rate 14.\"],\n",
    "    [\"The patient is an 83-year-old female with a history of hypertension, hypercholesterolemia, who presented with a large intraparenchymal cerebral hemorrhage complicated by obstructive hydrocephalus.\"],\n",
    "    [\"Sodium: 142 mmol/L, potassium: 4.0 mmol/L, chloride: 106 mmol/L, bicarb: 21 mmol/L, BUN: 15 mg/dL, creatinine: 0.6 mg/dL, glucose: 145 mg/dL.\"],\n",
    "    [\"CBC is as follows: White blood cell count 11.1, hematocrit 42.7, platelets 183.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-1019txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 408.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#832\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What were the patient's conditions on discharge?\",\n",
    "    \"What medications is the patient currently taking?\",\n",
    "    \"Does the patient have a history of diabetes?\",\n",
    "    \"What is the patient’s blood pressure on examination?\",\n",
    "    \"What is the patient’s baseline creatinine level? \",\n",
    "    \"What is the patient's age?\",\n",
    "    \"What follow-up instructions were given to the patient?\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"The patient was discharged home in stable condition post-CABG, with a history of myocardial infarction, hypercholesterolemia, insulin-dependent diabetes mellitus, hypertension, and possible chronic renal insufficiency.\"],\n",
    "    [\"The patient is taking NPH insulin 45 units subcutaneously twice per day, Lipitor 80 mg by mouth once per day, Aspirin, Norvasc, Zocor, Lopressor 25 mg by mouth twice per day, Heparin, and Intravenous Integrilin.\"],\n",
    "    [\"Yes, the patient has a history of insulin-dependent diabetes mellitus.\"],\n",
    "    [\"139/65\"],\n",
    "    [\"1.3\"],\n",
    "    [\"62\"],\n",
    "    [\"He was continued on his heparin, nitroglycerin, and Integrilin drips.|The patient was discharged to home on .|1.  Metoprolol 20 mg by mouth twice per day.|.  Lasix 20 mg by mouth twice per day (times seven days).|.  Colace 100 mg by mouth twice per day.|.  Aspirin 325 mg by mouth once per day.|.  Percocet 5/325-mg tablets one to two tablets by mouth q.4h. as needed (for pain).|.  Lipitor 80 mg by mouth once per day.|.  Captopril 25 mg by mouth three times per day.|1.  Status post coronary artery bypass graft times four.|.  Status post myocardial infarction times two.|.  Status post percutaneous transluminal coronary angioplasty with stent in .|.  Hypercholesterolemia.|.  Insulin-dependent diabetes mellitus.|.  Hypertension.|.  Question chronic renal insufficiency.|The patient was discharged to home.|Condition on discharge was stable on .\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-832txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1369.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#826\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"Does the patient have any known drug allergies?\",\n",
    "    \"What is the patient's smoking history?\",\n",
    "    \"What was the cause of the patient's death?\",\n",
    "    \"What was the patient admitted for?\",\n",
    "    \"Has the patient got a history of diabetes?\",\n",
    "    \"Does the patient use cigarettes or alcohol?\",\n",
    "    \"Did the patient take imaging studies?\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"Patient recorded as having No Known Allergies to Drugs.\"],\n",
    "    [\"Prior 70 pack year smoking history, no EtOH.\"],\n",
    "    [\"GI bleed respiratory failure\"],\n",
    "    [\"Evaluation of new right-sided weakness.\"],\n",
    "    [\"Yes.\"],\n",
    "    [\"Smoke.\"],\n",
    "    [\"Yes.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-826txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1046.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#629\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"Does the patient have any known drug allergies?\",\n",
    "    \"How often does the patient consume alcohol?\",\n",
    "    \"What symptoms should prompt the patient to call the doctor's office or seek immediate medical attention?\",\n",
    "    \"What are the current findings regarding the chest tubes?\",\n",
    "    \"Are there any new lung findings on the recent imaging?\",\n",
    "    \"What should the patient do regarding tube feeds?\",\n",
    "    \"Did the patient take imaging studies?\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"No,patient recorded as having no known allergies to drugs.\"],\n",
    "    [\"Five times per week(+EtOH 5x/wk).\"],\n",
    "    [\"Fever, chest pain, shortness of breath, nausea, vomiting, constipation, abdominal pain, diarrhea.\"],\n",
    "    [\"Two left-sided chest tubes are in unchanged position. A tiny left apical pneumothorax is stable in appearance. A small left-sided pleural effusion and atelectasis within the left lower lobe are unchanged.\"],\n",
    "    [\"No new opacities are seen within the lungs.\"],\n",
    "    [\"The patient should remain NPO (nothing by mouth) and continue with tube feeds for the next 3 weeks, as per VNA instructions.\"],\n",
    "    [\"Yes.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-629txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/transformers/generation/utils.py:1363: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1011.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#615\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What is the patient's age and gender?\",\n",
    "    \"What caused the patient's motor vehicle collision?\",\n",
    "    \"What was the patient's GCS score upon arrival?\",\n",
    "    \"What were the injuries sustained by the patient?\",\n",
    "    \"What did the patient's official CT read show?\",\n",
    "    \"What are the patient's current medications?\",\n",
    "    \"Does the patient have any known drug allergies?\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"The patient is a 22 year old male.\"],\n",
    "    [\"The patient fell asleep at the wheel.\"],\n",
    "    [\"The patient arrived with a GCS of 5.\"],\n",
    "    [\"The patient sustained a grade III/IV splenic laceration, small left pneumothorax, pulmonary contusions, left rib fractures (ribs eight, nine, and ten), small pelvic rami superior and inferior fracture with intramuscular hematoma.\"],\n",
    "    [\"The patient's official CT read showed a splattered spleen with hemoperitoneum, grade III/IV splenic laceration, the hilum appeared to be intact.\"],\n",
    "    [\"Wellbutrin 200 mg orally twice a day, Zoloft 50 mg orally once daily, and Ambien as needed.\"],\n",
    "    [\"No.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-615txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1482.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#601\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What is the patient's age?\",\n",
    "    \"What were her vital signs in the emergency room?\",\n",
    "    \"What did CXR show?\",\n",
    "    \"Why was she transferred to the CCU?\",\n",
    "    \"What did the patient transfer to the CCU for?\",\n",
    "    \"What did the patient diagnosed with?\",\n",
    "    \"What did the patient discharge?\"\n",
    "  \n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"The patient is a 22 year old male.\"],\n",
    "    [\"The patient fell asleep at the wheel.\"],\n",
    "    [\"The patient arrived with a GCS of 5.\"],\n",
    "    [\"The patient sustained a grade III/IV splenic laceration, small left pneumothorax, pulmonary contusions, left rib fractures (ribs eight, nine, and ten), small pelvic rami superior and inferior fracture with intramuscular hematoma.\"],\n",
    "    [\"The patient was transferred to the CCU for further monitoring and management.\"],\n",
    "    [\"Rheumatic heart disease, rapid atrial-fibrillation, strong smoking history, and COPD who presents with shortness of breath.\"],\n",
    "    [\"The patient was discharged on diltiazem for rate control and with a heart monitor.\"]\n",
    "                 ]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-601txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1107.80 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#563\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What is the patient's age?\",\n",
    "    \"What were her vital signs in the emergency room?\",\n",
    "    \"Has the patient got a history of diabetes?\",\n",
    "    \"Is the patient scheduled to follow up with a pulmonologist?\",\n",
    "    \"Did the patient receive medications in the emergency room?\",\n",
    "    \"Did the patient take imaging studies?\",\n",
    "    \"Was imaging done to assess the patient's lung condition?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    [\"55\"],\n",
    "    [\"Temperature 97.3°F, heart rate 109, blood pressure 101/69, respiratory rate 20, oxygen level 98% on 6 liters of oxygen, 94% on room air.\"],\n",
    "    [\"No.\"],\n",
    "    [\"Yes, she is scheduled to follow up with a pulmonologist.\"],\n",
    "    [\"Yes, she was treated with Combivent nebulizations three times, received 5 liters of normal saline intravenously, was given Levofloxacin 500 mg intravenously for suspected pneumonia, and received Solumedrol 125 mg intravenously to reduce airway inflammation.\"],\n",
    "    [\"Yes\"],\n",
    "    [\"Yes, chest X-ray was performed.\"]\n",
    "                 ]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-563txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1528.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#417\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What is the patient's age?\",\n",
    "    \"What is the patient's medical history?\",\n",
    "    \"What allergies did the patient have?\",\n",
    "    \"What were the patient's main symptoms upon presenting to the Emergency Department?\",\n",
    "    \"What were the patient's vital signs in the Emergency Department? \",\n",
    "    \"What did the patient's chest X-ray show?\",\n",
    "    \"What were the main diagnoses for the patient?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    [\"89\"],\n",
    "    [\"A history of chronic obstructive pulmonary disease and ITP, who presented to the Emergency Department after a few hour history of chest and abdominal discomfort, increasing shortness of breath, and nausea with an episode of vomiting x1. \"],\n",
    "    [\"Penicillin produces a rash,Aspirin produces GI irritation.\"],\n",
    "    [\"He presented to the Emergency Department after a few hour history of chest and abdominal discomfort, increasing shortness of breath, and nausea with an episode of vomiting x1. He notes chest pressure with radiation to the back into the left arm, severity and associated epigastric discomfort with nausea and vomiting x1 in the Emergency Department.\"],\n",
    "    [\"Temperature 100.5, blood pressure 99/50, heart rate 126, respiratory rate 32 decreasing to 34 with nebulizer treatment, and O2 saturation 94% on 2 liters.\"],\n",
    "    [\"Left lower lung zone opacity, mild congestive heart failure.\"],\n",
    "    [\"An 89-year-old male with a history of chronic obstructive pulmonary disease and ITP, who presented with fever, elevated white count, and evidence of pneumonia on chest x-ray with suspected sepsis and chronic obstructive pulmonary disease exacerbation.\"]\n",
    "                 ]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-417txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 1154.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#403\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What is the patient's age?\",\n",
    "    \"Did the patient have any allergies to drugs?\",\n",
    "    \"What was the temperature of the patient at nursing home?\",\n",
    "    \"What findings were noted on the CXR?\",\n",
    "    \"Who was scheduled for the patient's follow-up care?\",\n",
    "    \"What measures were taken for the patient during his hospital stay?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    [\"89\"],\n",
    "    [\"A history of chronic obstructive pulmonary disease and ITP, who presented to the Emergency Department after a few hour history of chest and abdominal discomfort, increasing shortness of breath, and nausea with an episode of vomiting x1. \"],\n",
    "    [\"99.6\"],\n",
    "    [\"CXR showed new LLL opacity.\"],\n",
    "    [\"neurologist Dr.\"],\n",
    "    [\"During his hospital stay his LFTs/bili and coags remained stable.  He underwent an abdominal U/S of liver w/ normal TIPS evaluation with wall-to-wall flow. No ascites identified.  He was continued on lactulose and rifaxamin.\"]\n",
    "                 ]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-403txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1596.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#371\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What is the patient's age?\",\n",
    "    \"What are the discharge instructions for the patient?\",\n",
    "    \"What surgery did the patient undergo?\",\n",
    "    \"What medications is the patient prescribed?\",\n",
    "    \"What imaging studies were performed on the patient?\",\n",
    "    \"How was the patient's lung and heart status postoperatively?\",\n",
    "    \"What conditions did patient get a history of?\"\n",
    "\n",
    "]\n",
    "\n",
    "ground_truths = [[\"66\"],\n",
    "                 [\"Patient will be discharged to home with instructions to followup with Dr.  in  weeks, and he will have a follow-up CT angiogram here in about one month.\"],\n",
    "                 [\"An endovascular repair for an abdominal aortic aneurysm.\"],\n",
    "                 [\"Atorvastatin 20 mg daily, Colchicine 0.6 mg daily, Digoxin 0.25 mg daily, Lasix 120 mg daily, Lopressor XL 150 mg daily, Moexipril 7.5 mg daily, Percocet 1-2 tablets every 4-6 hours as needed, Coumadin 5 mg daily at bedtime, Levaquin 500 mg daily for 10 days\"],\n",
    "                 [\"CT scan.\"],\n",
    "                 [\"The patient's pulmonary status improved after the diuresis, and patient subsequently underwent a bronch, which showed no plugging, no secretions, and no signs of CHF.\"],\n",
    "                 [\"Coronary artery disease, CHF,Abdominal aortic aneurysm\"]\n",
    "                 ]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-371txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/transformers/generation/utils.py:1363: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 2696.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#365\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"How old is the patient?\",\n",
    "    \"What medications are the patient taking?\",\n",
    "    \"Has the patient got a history of diabetes?\",\n",
    "    \"What did initial lab data show?\",\n",
    "    \"What is the plan for the patient's follow-up?\",\n",
    "    \"What did the patiet do well in?\"\n",
    "\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    ['52'],\n",
    "    ['Cyclosporin 100 mg b.i.d., Neurontin 100 mg t.i.d., Lipitor 20 mg q.d., Fentanyl patch 25 q.72, sliding scale Insulin, Cefazolin IV, Cipro 500 q.d., Mucomyst 600 b.i.d., Colace 100 b.i.d., Lasix 80 p.o. b.i.d., Lopressor 75 mg p.o. b.i.d., Prednisone taper, Zantac, Enteric Coated Aspirin q.d., NPH 4 U subcue at 6:30 a.m. and 4:30 p.m.'],\n",
    "    ['Yes, he has a history of diabetes.'],\n",
    "    ['A white count which was 19.1, hematocrit 30.0, platelet count 66,000; INR 1.1, PTT 58.0; sodium 128, potassium 4.3, chloride 93, bicarb 23, BUN 78, creatinine 1.8, glucose 255, CK 45, calcium 8.5, magnesium 2.2, phosphorus 4.2; cyclosporin level was normal at 151.'],\n",
    "    ['The patient should follow-up with his primary cardiologist Dr.   in one month.  He will be evaluated at the  Hospital for possible AKA. Cardiology recommended that the surgery be done emergently as our Vascular surgeons feel that it should be postponed for two weeks to one month until the Plavix can be discontinued, as it is imperative that the Aspirin and Plavix not be stopped even for an operation, as he at high risk for stent reclosure.'],\n",
    "    ['He did well continuing on his Cyclosporin for status post renal transplant.']\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-365txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1255.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#359\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"How old is the patient?\",\n",
    "    \"What surgery did the patient undergo?\",\n",
    "    \"What is the patient's blood pressure?\",\n",
    "    \"What allergies did the patient have?\",\n",
    "    \"What imaging studies were performed on the patient?\",\n",
    "    \"Has the patient got a history of diabetes\",\n",
    "    \"Were there any problems after the operation?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    ['76'],\n",
    "    ['Elective hip surgery, specifically an open reduction and internal fixation of the left hip, for revision due to nonunion of a previous hip fracture'],\n",
    "    ['BP 156/70'],\n",
    "    ['The patient is allergic to sulfa drugs, which cause a rash.'],\n",
    "    ['Chest x-ray,CT scan of the head'],\n",
    "    ['Yes'],\n",
    "    ['No, there were no complications.']\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-359txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 271.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#239\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What are the patient's vital signs upon admission?\",\n",
    "    \"Describe the patient's cardiovascular status\",\n",
    "    \"What is the patient's blood pressure reading?\",\n",
    "    \"Does the patient have any allergies?\",\n",
    "    \"What are the patient's conditions?\",\n",
    "    \"What medication is the patient taking?\"\n",
    "\n",
    "]\n",
    "\n",
    "ground_truths = [[\"BP 149/86, heart rate 72, respiratory rate 16, and saturations 100%, intubated on ventilator.\"],\n",
    "                 [\"Cardiovascular: Regular rate and rhythm, harsh S1 and S2 sounds, no murmur.\"],\n",
    "                 [\"BP 149/86\"],\n",
    "                 [\"No known allergies.\"],\n",
    "                 [\"Intubated, young-appearing man attempting to pull at the ET tube with his left hand. HEENT: Nonicteric. Neck: Supple, no carotid bruits. Chest was clear to auscultation. Cardiovascular: Regular rate and rhythm, harsh S1 and S2 sounds, no murmur. Abdomen: Soft, nontender, positive bowel sounds. Extremities: No edema. Neurologically: Does not open eyes to voice or painful stimulation. Cranial nerves: Pupils| mm down to 1 bilaterally. EOMs full. Positive doll's eyes. Corneal reflexes: Absent bilaterally. Facial symmetry: ET restricts the lower face, but upper face appears wrinkling, symmetrically. Gag reflex: Gagging on the ET. Motor: Increased tone in all four extremities. Moves left side spontaneously, reaching and grabbing for the ET tube with the left hand. No spontaneous movement of the right hemibody. Decerebrate posturing of the right arm with pain and flexes knees and ankle with pain applied to both legs. Purposely withdraws, localizes with the left arm.\"],\n",
    "                 [\"Coumadin\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-239txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 432.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#205\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"Why was the patient admitted to the hospital?\",\n",
    "    \"What allergie did the patient have?\",\n",
    "    \"What imaging studies were performed on the patient?\",\n",
    "    \"What medication is the patient taking?\",\n",
    "    \"What were the results of chest CT?\",\n",
    "    \"What follow-up instructions were given to the patient?\"\n",
    "\n",
    "]\n",
    "\n",
    "ground_truths = [[\"He was stabbed in the back three times.\"],\n",
    "                 [\"No known drug allergies.\"],\n",
    "                 [\"Chest and pelvic x-rays were normal. Head CT was negative. Abdominal CT was within normal limits. Chest CT showed a right pneumothorax.\"],\n",
    "                 [\"Methadone 5 mg po b.i.d. for five days only with Ibuprofen 400 mg t.i.d. Cefalexin 500 mg b.i.d. times four days. Pantoprazole 40 mg po q.d. Dilaudid 2 mg po q 6 hours prn for five days.\"],\n",
    "\n",
    "                 [\"Chest CT showed a right pneumothorax.\"],\n",
    "                 [\"The patient can follow up at the Trauma Clinic if there are any new developments with the wounds or problems relating to this injury. Otherwise he is to obtain a primary care physician for long term healthcare.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-205txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 1405.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#198\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"Why was the patient admitted to the hospital?\",\n",
    "    \"What allergie did the patient have?\",\n",
    "    \"What imaging studies were performed on the patient?\",\n",
    "    \"What medication is the patient taking?\",\n",
    "    \"What were the results of chest CT?\",\n",
    "    \"What follow-up instructions were given to the patient?\"\n",
    "\n",
    "]\n",
    "\n",
    "ground_truths = [[\"He was stabbed in the back three times.\"],\n",
    "                 [\"No known drug allergies.\"],\n",
    "                 [\"Chest and pelvic x-rays were normal. Head CT was negative. Abdominal CT was within normal limits. Chest CT showed a right pneumothorax.\"],\n",
    "                 [\"Methadone 5 mg po b.i.d. for five days only with Ibuprofen 400 mg t.i.d. Cefalexin 500 mg b.i.d. times four days. Pantoprazole 40 mg po q.d. Dilaudid 2 mg po q 6 hours prn for five days.\"],\n",
    "\n",
    "                 [\"Chest CT showed a right pneumothorax.\"],\n",
    "                 [\"The patient can follow up at the Trauma Clinic if there are any new developments with the wounds or problems relating to this injury. Otherwise he is to obtain a primary care physician for long term healthcare.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-198txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 2442.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#167\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What is the patient's age?\",\n",
    "    \"What medications is the patient currently taking for maintenance?\",\n",
    "    \"Has the patient got a history of drug?\",\n",
    "    \"What allergies did the patient have?\",\n",
    "    \"What were the results of the patient's chest X-ray on admission?\",\n",
    "    \"How many loose stools does the patient report per day?\"\n",
    "\n",
    "]\n",
    "\n",
    "ground_truths = [[\"51 years old\"],\n",
    "                 [\"Methadone 145 mg q. d.|Lives in .|History of alcohol abuse.  Denies any cigarette smoking.|On admission, temperature 98.1, heart rate 65, blood pressure 122/84 with a respiratory rate of 18,|8% on room air.  He was alert and oriented, no acute distress.  Lungs clear to auscultation bilaterally.  Heart regular rate and rhythm.  Abdomen soft, obese, positive bowel sounds, nonfocal abdomen, tender, negative rebound, negative hemorrhoids, positive umbilical hernia.  Rectal, guaiac negative, no hemorrhoids.  Extremities, positive venous changes and no edema.|On admission, the patient had a chest x-ray that showed no acute process, no suspicious nodules.  EKG on , sinus bradycardia, rate 49, inferior lateral flat T-waves.  On , CT of the thorax was stable, no lesions.|The patient was admitted to the transplant service.  He was made NPO after midnight.  IV fluid was started.  Lab work was sent off to use preop for the OR. Labs preop:  White count 3.7, hematocrit\"],\n",
    "                 [\"Yes, he had a history of alcohol and IV drug abuse.\"],\n",
    "                 [\"Penicillin\"],\n",
    "                 [\"The chest x-ray showed no acute process, no suspicious nodules.\"],\n",
    "                 [\"x10 per 24 hours\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-167txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/transformers/generation/utils.py:1363: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 2249.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#79\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"What were the maternal conditions during pregnancy?\",\n",
    "    \"What were the newborn's initial clinical findings?\",\n",
    "    \"What respiratory support did the newborn receive?\",\n",
    "    \"What is the screen status of the newborn?\",\n",
    "    \"What medication is the patient taking?\",\n",
    "    \"What imaging studies were performed?\"\n",
    "\n",
    "]\n",
    "\n",
    "ground_truths = [[\"She was born to a 30-year-old G1/P0 (to 1) woman whose pregnancy was notable for an admission to with cervical shortening on. She was treated with bed rest and betamethasone. Mother's history is notable for insulin-dependent diabetes and a seizure disorder (for which she is being treated with Trileptal).\"],\n",
    "                 [\"Birth weight was 775 grams. She is a patent nondysmorphic infant with a foul smell noted. Skin with bruising noted about the trunk. HEENT exam was within normal limits. Cardiovascular exam revealed S1 and S2 without murmur. Lungs revealed coarse breath sounds bilaterally. The abdomen was benign. Neurologic exam was nonfocal. Tone was slightly decreased throughout. The patient was moving all 4 extremities. Hips were normal. Anus was patent. The spine was intact.\"],\n",
    "                 [\"The patient was intubated in the delivery room. Received 2 doses of surfactant and is currently in SIMV at settings of 16/5 at a rate of 18. FiO2 is room air.\"],\n",
    "                 [\"Has not been sent.\"],\n",
    "                 [\"The patient is currently on ampicillin and gentamicin.\"],\n",
    "                 [\"The patient was started on phototherapy for an 8-hour bilirubin level of 3.5/4/0.2.\"]\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('t5-79txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#45\n",
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"Does the patient have any known drug allergies?\",\n",
    "    \"What languages does the patient speak?\",\n",
    "    \"What was the patient's sodium level at 04:51 PM?\",\n",
    "    \"What was the patient's albumin level?\",\n",
    "    \"What abnormalities were found on the MRI?\",\n",
    "    \"What were the findings on the CT?\"\n",
    "]\n",
    "\n",
    "ground_truths = [[\"No.\"],\n",
    "                 [\"Italian, some english\"],\n",
    "                 [\"SODIUM-137\"],\n",
    "                 [\"ALBUMIN-3.2*\"],\n",
    "                 [\"On diffusion-weighted images there is a small area of restricted diffusion along the falx within the left occipitotemporal lobe. It is also bright on FLAIR-weighted images and may represent a subacute infarct. Clinical correlation is recommended. On gradient echo images there is a large area of intraparenchymal hemorrhage within the right parietal lobe and left thalamus which following administration of gadolinium reveals ring-enhancing lesions. These are suspicious for hemorrhagic metastases given the patient's history. Additional ring-enhancing lesions throughout the supra- and infratentorial compartments are visualized.\"],\n",
    "                 [\"Stable appearance of right parietal lobe and left thalamic hemorrhages, which are concerning for hemorrhagic metastasis in this patient with known metastatic lung carcinoma to the brain.\"]\n",
    "\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 781.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('t5-45txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
       "    num_rows: 7\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the patient's age and gender?</td>\n",
       "      <td>57-year-old</td>\n",
       "      <td>[The patient is a 57-year-old female with a hi...</td>\n",
       "      <td>[The patient is a 57-year-old female.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What did the patient have a history of?</td>\n",
       "      <td>Hypertension and hypercholesterolemia</td>\n",
       "      <td>[The patient is a 57-year-old female with a hi...</td>\n",
       "      <td>[Hypertension and hypercholesterolemia.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why did the patient come to the hospital?</td>\n",
       "      <td>She was diagnosed with GERD-like symptoms. She...</td>\n",
       "      <td>[The patient is a 57-year-old female with a hi...</td>\n",
       "      <td>[She came due to chest pain that started at 4:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What medications was she discharged with?</td>\n",
       "      <td>Coumadin</td>\n",
       "      <td>[The patient is a 57-year-old female with a hi...</td>\n",
       "      <td>[She was discharged on Aspirin, Lisinopril, To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the patient's vital signs on admission?</td>\n",
       "      <td>afebrile, blood pressure 146/88, pulse 71, res...</td>\n",
       "      <td>[The patient is a 57-year-old female with a hi...</td>\n",
       "      <td>[Vital signs: On admission, the patient was af...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0              What is the patient's age and gender?   \n",
       "1            What did the patient have a history of?   \n",
       "2          Why did the patient come to the hospital?   \n",
       "3          What medications was she discharged with?   \n",
       "4  What were the patient's vital signs on admission?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                        57-year-old   \n",
       "1              Hypertension and hypercholesterolemia   \n",
       "2  She was diagnosed with GERD-like symptoms. She...   \n",
       "3                                           Coumadin   \n",
       "4  afebrile, blood pressure 146/88, pulse 71, res...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [The patient is a 57-year-old female with a hi...   \n",
       "1  [The patient is a 57-year-old female with a hi...   \n",
       "2  [The patient is a 57-year-old female with a hi...   \n",
       "3  [The patient is a 57-year-old female with a hi...   \n",
       "4  [The patient is a 57-year-old female with a hi...   \n",
       "\n",
       "                                       ground_truths  \n",
       "0             [The patient is a 57-year-old female.]  \n",
       "1           [Hypertension and hypercholesterolemia.]  \n",
       "2  [She came due to chest pain that started at 4:...  \n",
       "3  [She was discharged on Aspirin, Lisinopril, To...  \n",
       "4  [Vital signs: On admission, the patient was af...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_input_df = dataset.to_pandas()\n",
    "display(ragas_input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset= Dataset.load_from_disk('t5-826txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_ragas_dataset(dataset):\n",
    "  result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "    \n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_correctness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "qa_result = evaluate_ragas_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.0000, 'faithfulness': 0.6667, 'answer_relevancy': 0.7758, 'context_recall': 0.8571, 'context_relevancy': 0.2000, 'answer_correctness': 0.8061, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#1227\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.7143, 'faithfulness': 0.8810, 'answer_relevancy': 0.8762, 'context_recall': 1.0000, 'context_relevancy': 0.0202, 'answer_correctness': 0.8482, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#1031\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.2857, 'faithfulness': 0.7429, 'answer_relevancy': 0.8435, 'context_recall': 0.9524, 'context_relevancy': 0.0251, 'answer_correctness': 0.8048, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#1025\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.4286, 'faithfulness': 0.7041, 'answer_relevancy': 0.8465, 'context_recall': 1.0000, 'context_relevancy': 0.0437, 'answer_correctness': 0.7270, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#1019\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.5714, 'faithfulness': 0.7226, 'answer_relevancy': 0.8399, 'context_recall': 1.0000, 'context_relevancy': 0.1670, 'answer_correctness': 0.6854, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#832\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.2857, 'faithfulness': 0.6508, 'answer_relevancy': 0.8236, 'context_recall': 0.5000, 'context_relevancy': 0.0857, 'answer_correctness': 0.6825, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#826\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.4286, 'faithfulness': 0.8082, 'answer_relevancy': 0.7927, 'context_recall': 0.8571, 'context_relevancy': 0.0840, 'answer_correctness': 0.7673, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#629\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.5714, 'faithfulness': 0.7381, 'answer_relevancy': 0.8399, 'context_recall': 1.0000, 'context_relevancy': 0.0714, 'answer_correctness': 0.8357, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#615\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.2857, 'faithfulness': 0.8571, 'answer_relevancy': 0.8438, 'context_recall': 0.8571, 'context_relevancy': 0.0434, 'answer_correctness': 0.8730, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#601\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.2857, 'faithfulness': 0.6063, 'answer_relevancy': 0.8243, 'context_recall': 0.6857, 'context_relevancy': 0.0155, 'answer_correctness': 0.7254, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#563\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.5714, 'faithfulness': 0.7520, 'answer_relevancy': 0.8560, 'context_recall': 0.8571, 'context_relevancy': 0.0260, 'answer_correctness': 0.6875, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#417\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.3333, 'faithfulness': 0.7000, 'answer_relevancy': 0.8255, 'context_recall': 1.0000, 'context_relevancy': 0.0476, 'answer_correctness': 0.7803, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#403\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.6667, 'faithfulness': 0.7500, 'answer_relevancy': 0.8268, 'context_recall': 0.8889, 'context_relevancy': 0.0090, 'answer_correctness': 1.0000, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#365\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.1429, 'faithfulness': 0.7143, 'answer_relevancy': 0.7828, 'context_recall': 0.9643, 'context_relevancy': 0.0373, 'answer_correctness': 0.9048, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#359\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.1667, 'faithfulness': 0.9028, 'answer_relevancy': 0.8545, 'context_recall': 1.0000, 'context_relevancy': 0.0682, 'answer_correctness': 0.9167, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#239\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.0000, 'faithfulness': 0.6667, 'answer_relevancy': 0.8100, 'context_recall': 0.1667, 'context_relevancy': 0.0154, 'answer_correctness': 0.5625, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#205\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.5000, 'faithfulness': 0.9167, 'answer_relevancy': 0.8500, 'context_recall': 1.0000, 'context_relevancy': 0.0458, 'answer_correctness': 0.8125, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#198\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 1.0000, 'faithfulness': 0.5069, 'answer_relevancy': 0.7992, 'context_recall': 0.8333, 'context_relevancy': 0.1275, 'answer_correctness': 0.7917, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#45\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.5000, 'faithfulness': 0.8333, 'answer_relevancy': 0.8241, 'context_recall': 0.9524, 'context_relevancy': 0.0871, 'answer_correctness': 0.8438, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#167\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.6667, 'faithfulness': 0.9833, 'answer_relevancy': 0.8422, 'context_recall': 0.9583, 'context_relevancy': 0.1239, 'answer_correctness': 0.8583, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "#79\n",
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = qa_result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"t5_45txt_result.csv\")\n",
    "#df.to_csv(\"t5_79txt_result.csv\")\n",
    "# #df.to_csv(\"t5_167txt_result.csv\")\n",
    "#df.to_csv(\"t5_198txt_result.csv\")\n",
    "#df.to_csv(\"t5_205txt_result.csv\")\n",
    "#df.to_csv(\"t5_239txt_result.csv\")\n",
    "#df.to_csv(\"t5_359txt_result.csv\")\n",
    "#df.to_csv(\"t5_365txt_result.csv\")\n",
    "#df.to_csv(\"t5_371txt_result.csv\")\n",
    "#df.to_csv(\"t5_403txt_result.csv\")\n",
    "#df.to_csv(\"t5_417txt_result.csv\")\n",
    "#df.to_csv(\"t5_563txt_result.csv\")\n",
    "#df.to_csv(\"t5_601txt_result.csv\")\n",
    "#df.to_csv(\"t5_615txt_result.csv\")\n",
    "#df.to_csv(\"t5_629txt_result.csv\")\n",
    "#df.to_csv(\"t5_826txt_result.csv\")\n",
    "#df.to_csv(\"t5_832txt_result.csv\")\n",
    "#df.to_csv(\"t5_1019txt_result.csv\")\n",
    "#df.to_csv(\"t5_1025txt_result.csv\")\n",
    "#df.to_csv(\"t5_1031txt_result.csv\")\n",
    "df.to_csv(\"t5_1227txt_result.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
