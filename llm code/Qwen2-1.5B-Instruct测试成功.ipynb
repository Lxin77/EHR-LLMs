{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c067db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name emilyalsentzer/Bio_ClinicalBERT. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# some comment\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    ")\n",
    " \n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc3dd8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_211.txt\n"
     ]
    }
   ],
   "source": [
    "#onlyfiles = [f for f in listdir('top_1000_txt') if isfile(join('top_1000_txt', f))]\n",
    "onlyfiles=['note_211.txt']\n",
    "raw_documents = []\n",
    "for file in onlyfiles:\n",
    "    print(file)\n",
    "    raw_doc = TextLoader(f'top_1000_txt/{file}').load()\n",
    "    raw_documents.extend(raw_doc)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc4f16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5231739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 设置 Hugging Face 管道\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"Qwen/Qwen2-1.5B-Instruct\",\n",
    "    tokenizer=\"Qwen/Qwen2-1.5B-Instruct\",\n",
    "    max_length=2000,\n",
    "    temperature=0.1,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "# 创建本地 LLM\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# 创建检索器\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# 创建 QA 链\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=local_llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bddbd2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511461ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The patient is being treated with Dilantin. Dilantin is used to control seizures caused by certain types of\n",
      "brain tumors.\n",
      "The answer to this question can be inferred based on the information provided about the patient's treatment\n",
      "plan. Dilantin is commonly prescribed for controlling seizures associated with brain tumors, such as\n",
      "glioblastomas. Therefore, it is reasonable to assume that the patient is taking Dilantin as part of their\n",
      "treatment regimen. However, without further medical documentation or specific instructions from the healthcare\n",
      "provider, it cannot be confirmed definitively whether Dilantin is the only medication the patient is taking.\n",
      "It is important to note that the patient should continue to take Dilantin according to the prescription\n",
      "schedule recommended by their healthcare team. Additionally, it is essential to monitor the patient closely\n",
      "for any adverse effects related to the use of Dilantin and report them promptly to the healthcare providers.\n",
      "\n",
      "\n",
      "Sources:\n",
      "top_1000_txt/note_211.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What medication is the patient taking?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "735c0b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The patient does not mention anything about diabetes.\n",
      "The answer to the question cannot be determined based on the given information.\n",
      "\n",
      "\n",
      "Sources:\n",
      "top_1000_txt/note_211.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"Has the patient got a history of diabetes?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92627ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f46a1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "template = \"\"\"You are an expert clinical assistant. You will receive a collection of clinical notes. Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00f2c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=local_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bba9bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab501efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided document, there is no information about the patient's history of diabetes.\\n\\nAssistant: The answer is no. There is no mention of the patient having a history of diabetes in the given clinical note. Therefore, it can be concluded that the patient does not have a history of diabetes.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Has the patient got a history of diabetes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc273a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: Dilantin\\n\\nAssistant: The patient is being treated with Dilantin.\\n\\nExplanation: In the document provided, it mentions that the patient was prescribed Dilantin during their hospital stay. This information directly answers the question about what medication the patient is taking. The specific name of the medication is also mentioned, so this answer provides additional detail beyond just stating \"Dilantin\". Therefore, both aspects of the question (\"What medication is the patient taking?\" and \"Specifically, what is the name of the medication?\") are answered correctly here.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What medication is the patient taking?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "943ebf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"Has the patient got a history of diabetes?\",\n",
    "    \"What allergies did the patient have?\",\n",
    "    \"Does the patient use tobacco or alcohol?\",\n",
    "    \"What medication is the patient taking?\",\n",
    "    \"What measures were taken for the patient?\",\n",
    "    \"What imaging studies were performed on the patient?\",\n",
    "    \"What follow-up care was scheduled for the patient?\",\n",
    "    \"What did C-spine show?\",\n",
    "    \"Does the patient use alcohol?\",\n",
    "    \"Does the patient use cigarettes or alcohol?\",\n",
    "    \"Did patient use tobacco?\"\n",
    "]\n",
    "\n",
    "ground_truths = [[\"No.\"],\n",
    "                 [\"The patient has no known allergies to drugs.\"],\n",
    "                 [\"Yes, the patient occasionally uses tobacco (cigarettes) but denies alcohol use.\"],\n",
    "                 [\"Dilantin 100 IV TID.\"],\n",
    "                 [\"Intubation and placement of a left radial arterial line for close blood pressure monitoring with a goal of keeping systolic blood pressure under 140. head CT, C-spine, chest/abdomen/pelvis CT to assess injuries. The patient was started on Dilantin 100 IV TID. Monitoring in the Trauma Intensive Care Unit (TICU). Repeat head CT and gradual weaning. Discontinuation of the Foley catheter and intravenous lines.Transfer from the ICU to the general hospital floor.  MRI of the C-spine to evaluate for potential injuries, which showed no fractures or ligamentous injuries, leading to clearance of the C-spine and discontinuation of the C-collar.Evaluation by Neurosurgery and Physical Therapy, deeming the patient fit for discharge with instructions for home care and follow-up.\"],\n",
    "                 [\"The patient underwent head CT, C-spine, chest/abd/pelvis CT scans, and an MRI of the C-spine\"],\n",
    "                 [\"An outpatient CT scan was scheduled to be done in 2 weeks, and a follow-up clinic appointment was scheduled in 2 weeks after the CT scan.No need to follow up in the trauma clinic but the patient may call the clinic with any questions.\"],\n",
    "                 [\"The MRI of the C-spine showed no fractures or ligamentous injuries.\"],\n",
    "                 [\"No, the patient denies alcohol use.\"],\n",
    "                 [\"The patient occasionally uses cigarettes and denies alcohol use.\"],\n",
    "                 [\"Yes, the patient occasionally uses tobacco (cigarettes).\"]\n",
    "\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a68985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
       "    num_rows: 11\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "417de27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 11/11 [00:00<00:00, 2025.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('Qwen2-1.5B-Instruct-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e55ee98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has the patient got a history of diabetes?</td>\n",
       "      <td>Based on the provided document, there is no in...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[No.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What allergies did the patient have?</td>\n",
       "      <td>Answer: The document does not mention any know...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[The patient has no known allergies to drugs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does the patient use tobacco or alcohol?</td>\n",
       "      <td>Answer: The document does not mention whether ...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Yes, the patient occasionally uses tobacco (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What medication is the patient taking?</td>\n",
       "      <td>Answer: Dilantin\\n\\nAssistant: The patient is ...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Dilantin 100 IV TID.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What measures were taken for the patient?</td>\n",
       "      <td>Based on the provided clinical notes, here are...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Intubation and placement of a left radial art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  \\\n",
       "0  Has the patient got a history of diabetes?   \n",
       "1        What allergies did the patient have?   \n",
       "2    Does the patient use tobacco or alcohol?   \n",
       "3      What medication is the patient taking?   \n",
       "4   What measures were taken for the patient?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Based on the provided document, there is no in...   \n",
       "1  Answer: The document does not mention any know...   \n",
       "2  Answer: The document does not mention whether ...   \n",
       "3  Answer: Dilantin\\n\\nAssistant: The patient is ...   \n",
       "4  Based on the provided clinical notes, here are...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Patient recorded as having No Known Allergies...   \n",
       "1  [Patient recorded as having No Known Allergies...   \n",
       "2  [Patient recorded as having No Known Allergies...   \n",
       "3  [Patient recorded as having No Known Allergies...   \n",
       "4  [Patient recorded as having No Known Allergies...   \n",
       "\n",
       "                                       ground_truths  \n",
       "0                                              [No.]  \n",
       "1     [The patient has no known allergies to drugs.]  \n",
       "2  [Yes, the patient occasionally uses tobacco (c...  \n",
       "3                             [Dilantin 100 IV TID.]  \n",
       "4  [Intubation and placement of a left radial art...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_input_df = dataset.to_pandas()\n",
    "display(ragas_input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2b37ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset= Dataset.load_from_disk('Qwen2-1.5B-Instruct-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d972d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e7513b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_ragas_dataset(dataset):\n",
    "  result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "    \n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8001bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "087b64c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:26<00:00, 26.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_correctness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:43<00:00, 43.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "qa_result = evaluate_ragas_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76bf6e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.2727, 'faithfulness': 0.5960, 'answer_relevancy': 0.9434, 'context_recall': 1.0000, 'context_relevancy': 0.1193, 'answer_correctness': 0.7449, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be67c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = qa_result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee3a2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Qwen2-1.5B-Instruct_ragas_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
