{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name emilyalsentzer/Bio_ClinicalBERT. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# some comment\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    ")\n",
    " \n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_211.txt\n"
     ]
    }
   ],
   "source": [
    "#onlyfiles = [f for f in listdir('top_1000_txt') if isfile(join('top_1000_txt', f))]\n",
    "onlyfiles=['note_211.txt']\n",
    "raw_documents = []\n",
    "for file in onlyfiles:\n",
    "    print(file)\n",
    "    raw_doc = TextLoader(f'top_1000_txt/{file}').load()\n",
    "    raw_documents.extend(raw_doc)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=llm_model, openai_api_key=\"\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "template = \"\"\"You are an expert clinical assistant. You will receive a collection of clinical notes. You will summarize them in the style of a discharge summary.Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The patient was recorded as having No Known Allergies to Drugs.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('What allergies did the patient have?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"Has the patient got a history of diabetes?\",\n",
    "    \"What allergies did the patient have?\",\n",
    "    \"Does the patient use tobacco or alcohol?\",\n",
    "    \"What medication is the patient taking?\",\n",
    "    \"What measures were taken for the patient?\",\n",
    "    \"What imaging studies were performed on the patient?\",\n",
    "    \"What follow-up care was scheduled for the patient?\",\n",
    "    \"What were the results of the patient’s tests?\",\n",
    "    \"What did C-spine show?\",\n",
    "    \"Does the patient use alcohol?\",\n",
    "    \"Does the patient use cigarettes or alcohol?\",\n",
    "    \"Did patient use tobacco?\"\n",
    "]\n",
    "\n",
    "ground_truths = [[\"No.\"],\n",
    "                 [\"The patient has no known allergies to drugs.\"],\n",
    "                 [\"Yes, the patient occasionally uses tobacco (cigarettes) but denies alcohol use.\"],\n",
    "                 [\"Dilantin 100 IV TID.\"],\n",
    "                 [\"The patient was intubated, had a left radial arterial line placed for close BP monitoring, and was admitted to the TICU. A cervical collar was also placed and later removed after C-spine clearance.\"],\n",
    "                 [\"The patient underwent head CT, C-spine, chest/abd/pelvis CT scans, and an MRI of the C-spine\"],\n",
    "                 [\"An outpatient CT scan was scheduled to be done in 2 weeks, and a follow-up clinic appointment was scheduled in 2 weeks after the CT scan.No need to follow up in the trauma clinic but the patient may call the clinic with any questions.\"],\n",
    "                 [\"The patient’s tests showed a diffuse axonal injury and hemorrhagic shearing injuries with post-traumatic intraventricular and cisternal hemorrhagic foci on the head CT. The CT of the C-spine, chest/abd/pelvis was all negative. The MRI of the C-spine showed no fractures or ligamentous injuries.\"],\n",
    "                 [\"The CT of the C-spine showed no fractures or ligamentous injuries. \"],\n",
    "                 [\"No, the patient denies alcohol use.\"],\n",
    "                 [\"The patient occasionally uses cigarettes and denies alcohol use.\"],\n",
    "                 [\"Yes, the patient occasionally uses tobacco (cigarettes).\"]\n",
    "\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 12/12 [00:00<00:00, 1947.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('gpt3.5dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has the patient got a history of diabetes?</td>\n",
       "      <td>Based on the provided clinical notes, there is...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[No.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What allergies did the patient have?</td>\n",
       "      <td>The patient had No Known Allergies to Drugs.</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[The patient has no known allergies to drugs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does the patient use tobacco or alcohol?</td>\n",
       "      <td>The patient has occasional tobacco use (cigare...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Yes, the patient occasionally uses tobacco (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What medication is the patient taking?</td>\n",
       "      <td>The patient is taking Dilantin 100 IV TID.</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Dilantin 100 IV TID.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What measures were taken for the patient?</td>\n",
       "      <td>The patient, a 51-year-old with a closed head ...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[The patient was intubated, had a left radial ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  \\\n",
       "0  Has the patient got a history of diabetes?   \n",
       "1        What allergies did the patient have?   \n",
       "2    Does the patient use tobacco or alcohol?   \n",
       "3      What medication is the patient taking?   \n",
       "4   What measures were taken for the patient?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Based on the provided clinical notes, there is...   \n",
       "1       The patient had No Known Allergies to Drugs.   \n",
       "2  The patient has occasional tobacco use (cigare...   \n",
       "3         The patient is taking Dilantin 100 IV TID.   \n",
       "4  The patient, a 51-year-old with a closed head ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Patient recorded as having No Known Allergies...   \n",
       "1  [Patient recorded as having No Known Allergies...   \n",
       "2  [Patient recorded as having No Known Allergies...   \n",
       "3  [Patient recorded as having No Known Allergies...   \n",
       "4  [Patient recorded as having No Known Allergies...   \n",
       "\n",
       "                                       ground_truths  \n",
       "0                                              [No.]  \n",
       "1     [The patient has no known allergies to drugs.]  \n",
       "2  [Yes, the patient occasionally uses tobacco (c...  \n",
       "3                             [Dilantin 100 IV TID.]  \n",
       "4  [The patient was intubated, had a left radial ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_input_df = dataset.to_pandas()\n",
    "display(ragas_input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_ragas_dataset(dataset):\n",
    "  result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "    \n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_correctness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:19<00:00, 19.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "qa_result = evaluate_ragas_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.3333, 'faithfulness': 0.8275, 'answer_relevancy': 0.9162, 'context_recall': 1.0000, 'context_relevancy': 0.1094, 'answer_correctness': 0.8624, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = qa_result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"gpt3.5_ragas_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
