{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name emilyalsentzer/Bio_ClinicalBERT. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# some comment\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    ")\n",
    " \n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_211.txt\n"
     ]
    }
   ],
   "source": [
    "#onlyfiles = [f for f in listdir('top_1000_txt') if isfile(join('top_1000_txt', f))]\n",
    "onlyfiles=['note_211.txt']\n",
    "raw_documents = []\n",
    "for file in onlyfiles:\n",
    "    print(file)\n",
    "    raw_doc = TextLoader(f'top_1000_txt/{file}').load()\n",
    "    raw_documents.extend(raw_doc)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: gpt4all in /Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages (2.7.0)\n",
      "Requirement already satisfied: requests in /Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages (from gpt4all) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages (from gpt4all) (4.66.4)\n",
      "Requirement already satisfied: importlib-resources in /Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages (from gpt4all) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages (from importlib-resources->gpt4all) (3.19.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages (from requests->gpt4all) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages (from requests->gpt4all) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages (from requests->gpt4all) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liangxin/anaconda3/envs/vector/lib/python3.8/site-packages (from requests->gpt4all) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 4.11G/4.11G [04:31<00:00, 15.1MiB/s]\n",
      "Verifying: 100%|██████████| 4.11G/4.11G [00:08<00:00, 489MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(model_name=\"mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "                             n_threads = 4,\n",
    "                             allow_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import GPT4All\n",
    "llm = GPT4All(\n",
    "            model=\"mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "            max_tokens=300,\n",
    "            n_threads = 4, \n",
    "            temp=0.3,\n",
    "            top_p=0.2,\n",
    "            top_k=40,\n",
    "            n_batch=8,\n",
    "            seed=100,\n",
    "            allow_download=True,\n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "template = \"\"\"You are an expert clinical assistant. You will receive a collection of clinical notes. You will summarize them in the style of a discharge summary.Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: The patient had no known allergies to drugs.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('What allergies did the patient have?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "questions= [\n",
    "    \"Has the patient got a history of diabetes?\",\n",
    "    \"What allergies did the patient have?\",\n",
    "    \"Does the patient use tobacco or alcohol?\",\n",
    "    \"What medication is the patient taking?\",\n",
    "    \"What measures were taken for the patient?\",\n",
    "    \"What imaging studies were performed on the patient?\",\n",
    "    \"What follow-up care was scheduled for the patient?\",\n",
    "    \"What did C-spine show?\",\n",
    "    \"Does the patient use alcohol?\",\n",
    "    \"Does the patient use cigarettes or alcohol?\",\n",
    "    \"Did patient use tobacco?\"\n",
    "]\n",
    "\n",
    "ground_truths = [[\"No.\"],\n",
    "                 [\"The patient has no known allergies to drugs.\"],\n",
    "                 [\"Yes, the patient occasionally uses tobacco (cigarettes) but denies alcohol use.\"],\n",
    "                 [\"Dilantin 100 IV TID.\"],\n",
    "                 [\"Intubation and placement of a left radial arterial line for close blood pressure monitoring with a goal of keeping systolic blood pressure under 140. head CT, C-spine, chest/abdomen/pelvis CT to assess injuries. The patient was started on Dilantin 100 IV TID. Monitoring in the Trauma Intensive Care Unit (TICU). Repeat head CT and gradual weaning. Discontinuation of the Foley catheter and intravenous lines.Transfer from the ICU to the general hospital floor.  MRI of the C-spine to evaluate for potential injuries, which showed no fractures or ligamentous injuries, leading to clearance of the C-spine and discontinuation of the C-collar.Evaluation by Neurosurgery and Physical Therapy, deeming the patient fit for discharge with instructions for home care and follow-up.\"],\n",
    "                 [\"The patient underwent head CT, C-spine, chest/abd/pelvis CT scans, and an MRI of the C-spine\"],\n",
    "                 [\"An outpatient CT scan was scheduled to be done in 2 weeks, and a follow-up clinic appointment was scheduled in 2 weeks after the CT scan.No need to follow up in the trauma clinic but the patient may call the clinic with any questions.\"],\n",
    "                 [\"The MRI of the C-spine showed no fractures or ligamentous injuries.\"],\n",
    "                 [\"No, the patient denies alcohol use.\"],\n",
    "                 [\"The patient occasionally uses cigarettes and denies alcohol use.\"],\n",
    "                 [\"Yes, the patient occasionally uses tobacco (cigarettes).\"]\n",
    "\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "# 构建数据\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truths\": ground_truths\n",
    "}\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
       "    num_rows: 11\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 11/11 [00:00<00:00, 681.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('mistral-7b-instruct-v0.1.Q4_0.gguf-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has the patient got a history of diabetes?</td>\n",
       "      <td>Answer: No, there is no mention of diabetes in...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[No.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What allergies did the patient have?</td>\n",
       "      <td>Answer: The patient had no known allergies to ...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[The patient has no known allergies to drugs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does the patient use tobacco or alcohol?</td>\n",
       "      <td>Answer: The patient uses occasional tobacco (c...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Yes, the patient occasionally uses tobacco (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What medication is the patient taking?</td>\n",
       "      <td>Answer: The patient is not currently taking an...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Dilantin 100 IV TID.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What measures were taken for the patient?</td>\n",
       "      <td>Answer: The patient was intubated and had a le...</td>\n",
       "      <td>[Patient recorded as having No Known Allergies...</td>\n",
       "      <td>[Intubation and placement of a left radial art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  \\\n",
       "0  Has the patient got a history of diabetes?   \n",
       "1        What allergies did the patient have?   \n",
       "2    Does the patient use tobacco or alcohol?   \n",
       "3      What medication is the patient taking?   \n",
       "4   What measures were taken for the patient?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Answer: No, there is no mention of diabetes in...   \n",
       "1  Answer: The patient had no known allergies to ...   \n",
       "2  Answer: The patient uses occasional tobacco (c...   \n",
       "3  Answer: The patient is not currently taking an...   \n",
       "4  Answer: The patient was intubated and had a le...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Patient recorded as having No Known Allergies...   \n",
       "1  [Patient recorded as having No Known Allergies...   \n",
       "2  [Patient recorded as having No Known Allergies...   \n",
       "3  [Patient recorded as having No Known Allergies...   \n",
       "4  [Patient recorded as having No Known Allergies...   \n",
       "\n",
       "                                       ground_truths  \n",
       "0                                              [No.]  \n",
       "1     [The patient has no known allergies to drugs.]  \n",
       "2  [Yes, the patient occasionally uses tobacco (c...  \n",
       "3                             [Dilantin 100 IV TID.]  \n",
       "4  [Intubation and placement of a left radial art...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ragas_input_df = dataset.to_pandas()\n",
    "display(ragas_input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_ragas_dataset(dataset):\n",
    "  result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "    \n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_correctness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_similarity]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "qa_result = evaluate_ragas_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.2727, 'faithfulness': 0.8177, 'answer_relevancy': 0.9096, 'context_recall': 1.0000, 'context_relevancy': 0.1136, 'answer_correctness': 0.8605, 'answer_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "print(qa_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = qa_result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mistral-7b-instruct_ragas_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
